Python Version: 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]
PyTorch Version: 1.13.0+cu117
Number of GPUs: 1
Save path: exps/ResNetSE34L_AP
Embedding size is 512, encoder SAP.
Initialised AngleProto
Loaded the model on GPU 0
Initialised Adam optimizer
Initialised step LR scheduler
Model exps/ResNetSE34L_AP/model/model000000016.model loaded from previous state!
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())

 2023-01-20 09:57:44 Epoch 17, TEER/TAcc 62.65, TLOSS 1.467727, LR 0.000950
