{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(\"/workspaces/SpeakerVerification\")\n",
    "DATA = ROOT / \"data\"\n",
    "\n",
    "VOXCELEB1 = DATA / \"voxceleb1\"\n",
    "VOXCELEB2 = DATA / \"voxceleb2\"\n",
    "\n",
    "VOXCELEB1_DEEPLAKE = VOXCELEB1 / \"deeplake\" / \"VoxCeleb1\"\n",
    "VOXCELEB2_DEEPLAKE = VOXCELEB2 / \"deeplake\" / \"VoxCeleb2\"\n",
    "\n",
    "VOXCELEB1_ZIP_TEST  = VOXCELEB1 / \"zip\" / \"vox1_test.zip\"\n",
    "VOXCELEB1_ZIP_TRAIN = VOXCELEB1 / \"zip\" / \"vox1_dev.zip\"\n",
    "VOXCELEB2_ZIP_TEST  = VOXCELEB2 / \"zip\" / \"vox2_test.zip\"\n",
    "VOXCELEB2_ZIP_TRAIN = VOXCELEB2 / \"zip\" / \"vox2_dev.zip\"\n",
    "\n",
    "VOXCELEB1_EXTRACTED_TEST  = VOXCELEB1 / \"extracted\" / \"test\"\n",
    "VOXCELEB1_EXTRACTED_TRAIN = VOXCELEB1 / \"extracted\" / \"train\"\n",
    "VOXCELEB2_EXTRACTED_TEST  = VOXCELEB2 / \"extracted\" / \"test\"\n",
    "VOXCELEB2_EXTRACTED_TRAIN = VOXCELEB2 / \"extracted\" / \"train\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Zip Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "\n",
    "jobs = [\n",
    "    (VOXCELEB1_ZIP_TEST, VOXCELEB1_EXTRACTED_TEST),\n",
    "    (VOXCELEB1_ZIP_TRAIN, VOXCELEB1_EXTRACTED_TRAIN),\n",
    "    (VOXCELEB2_ZIP_TEST, VOXCELEB2_EXTRACTED_TEST),\n",
    "    (VOXCELEB2_ZIP_TRAIN, VOXCELEB2_EXTRACTED_TRAIN),\n",
    "]\n",
    "\n",
    "def extract(src: Path, dst: Path):\n",
    "    dst.mkdir(parents=True, exist_ok=True)\n",
    "    with ZipFile(src, \"r\") as zip:\n",
    "        zip.extractall(dst)\n",
    "\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     executor.map(lambda job: extract(*job), jobs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert m4a to wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "import ffmpeg\n",
    "\n",
    "\n",
    "def convert(audio: Path):\n",
    "    dst = audio.parent / f\"{audio.stem}.wav\"\n",
    "    audio_stream = ffmpeg.input(str(audio)).audio\n",
    "    output = ffmpeg.output(\n",
    "        audio_stream,\n",
    "        str(dst),\n",
    "        format=\"wav\",\n",
    "        acodec=\"pcm_s16le\",\n",
    "        ar=16000,\n",
    "        ac=1,\n",
    "    ).overwrite_output()\n",
    "    ffmpeg.run(output, quiet=True)\n",
    "    audio.unlink()\n",
    "\n",
    "audios = []\n",
    "for dataset in [VOXCELEB1_EXTRACTED_TEST, VOXCELEB1_EXTRACTED_TRAIN, VOXCELEB2_EXTRACTED_TEST, VOXCELEB2_EXTRACTED_TRAIN]:\n",
    "    for audio in dataset.glob(\"**/*.m4a\"):\n",
    "        audios.append(audio)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    executor.map(convert, audios)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate DeepLake dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "from pathlib import Path\n",
    "\n",
    "def generate(train: Path, test: Path, dest: Path, header: list, meta: dict):\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    dataset = deeplake.empty(dest, overwrite=True)\n",
    "    with dataset:\n",
    "        dataset.create_tensor(\n",
    "            \"Audio\",\n",
    "            htype=\"audio\",\n",
    "            sample_compression=\"wav\",\n",
    "        )\n",
    "\n",
    "        dataset.create_tensor(\n",
    "            \"Speaker ID\",\n",
    "            htype=\"class_label\",\n",
    "        )\n",
    "\n",
    "        dataset.create_tensor(\n",
    "            \"Video\",\n",
    "            htype=\"class_label\",\n",
    "        )\n",
    "\n",
    "        dataset.create_tensor(\n",
    "            \"Sample Name\",\n",
    "            htype=\"text\"\n",
    "        )\n",
    "        \n",
    "        for key in header:\n",
    "            dataset.create_tensor(\n",
    "                key,\n",
    "                htype=\"class_label\",\n",
    "            )\n",
    "    test_audios = [audio for audio in test.glob(\"**/*.wav\")]\n",
    "    train_audios = [audio for audio in train.glob(\"**/*.wav\")]\n",
    "    audios = [*test_audios, *train_audios]\n",
    "    for audio in audios:\n",
    "        video = audio.parent.name\n",
    "        speaker = audio.parent.parent.name\n",
    "        sample_name = f\"{speaker}/{video}/{audio.name}\"\n",
    "        with dataset:\n",
    "            sample = {\n",
    "                \"Audio\": deeplake.read(audio),\n",
    "                \"Speaker ID\": speaker,\n",
    "                \"Video\": video,\n",
    "                \"Sample Name\": sample_name,\n",
    "            }\n",
    "            for key in meta[speaker]:\n",
    "                sample[key] = meta[speaker][key]\n",
    "            dataset.append(sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate VoxCeleb1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VOXCELEB1 / \"lists\" / \"meta.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "header = lines[0].split(\"\\t\")\n",
    "header = header[1:]\n",
    "header = [h.strip() for h in header]\n",
    "meta = {}\n",
    "for line in lines[1:]:\n",
    "    try:\n",
    "        line = line.split(\"\\t\")\n",
    "        spkr = line[0]\n",
    "        line = line[1:]\n",
    "        meta[spkr] = {header[i]: line[i].strip() for i in range(len(header))}\n",
    "    except:\n",
    "        pass\n",
    "generate(VOXCELEB1_EXTRACTED_TRAIN, VOXCELEB1_EXTRACTED_TEST, VOXCELEB1_DEEPLAKE, header, meta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate VoxCeleb2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VOXCELEB2 / \"lists\" / \"meta.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "header = lines[0].split(\" ,\")\n",
    "header = header[1:]\n",
    "header = [h.strip() for h in header]\n",
    "meta = {}\n",
    "for line in lines[1:]:\n",
    "    try:\n",
    "        line = line.split(\" ,\")\n",
    "        spkr = line[0]\n",
    "        line = line[1:]\n",
    "        meta[spkr] = {header[i]: line[i].strip() for i in range(len(header))}\n",
    "    except:\n",
    "        pass\n",
    "generate(VOXCELEB2_EXTRACTED_TRAIN, VOXCELEB2_EXTRACTED_TEST, VOXCELEB2_DEEPLAKE, header, meta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Jan 11 2023, 15:12:53) [GCC 10.2.1 20210110]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "861a2f8c09f43a1383d5cddabe28a76b37a3607cb0ad9545d15c6c4469d688dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
