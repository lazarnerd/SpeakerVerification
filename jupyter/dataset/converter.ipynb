{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(\"/workspaces/SpeakerVerification\")\n",
    "DATA = ROOT / \"data\"\n",
    "\n",
    "VOXCELEB1 = DATA / \"voxceleb1\"\n",
    "VOXCELEB2 = DATA / \"voxceleb2\"\n",
    "\n",
    "VOXCELEB1_DEEPLAKE = VOXCELEB1 / \"deeplake\" / \"VoxCeleb1\"\n",
    "VOXCELEB2_DEEPLAKE = VOXCELEB2 / \"deeplake\" / \"VoxCeleb2\"\n",
    "\n",
    "VOXCELEB1_H5 = VOXCELEB1 / \"VoxCeleb1.h5\"\n",
    "VOXCELEB2_H5 = VOXCELEB2 / \"VoxCeleb2.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/SpeakerVerification/data/voxceleb1/deeplake/VoxCeleb1 loaded successfully.\n",
      "Dataset(path='/workspaces/SpeakerVerification/data/voxceleb1/deeplake/VoxCeleb1', tensors=['Audio', 'Gender', 'Nationality', 'Sample Name', 'Set', 'Speaker ID', 'VGGFace1 ID', 'Video'])\n",
      "\n",
      "   tensor        htype               shape              dtype  compression\n",
      "   -------      -------             -------            -------  ------- \n",
      "    Audio        audio     (153516, 63361:2318721, 1)   None      wav   \n",
      "   Gender     class_label         (153516, 1)          uint32    None   \n",
      " Nationality  class_label         (153516, 1)          uint32    None   \n",
      " Sample Name     text             (153516, 1)            str     None   \n",
      "     Set      class_label         (153516, 1)          uint32    None   \n",
      " Speaker ID   class_label         (153516, 1)          uint32    None   \n",
      " VGGFace1 ID  class_label         (153516, 1)          uint32    None   \n",
      "    Video     class_label         (153516, 1)          uint32    None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/SpeakerVerification/data/voxceleb1/deeplake/VoxCeleb1: 100%|██████████| 153516/153516 [53:50<00:00, 47.52it/s] \n"
     ]
    }
   ],
   "source": [
    "import deeplake\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def convert_audio(audio):\n",
    "    audio = audio.numpy()\n",
    "    audio = audio.reshape(audio.shape[0])\n",
    "    return audio\n",
    "\n",
    "def convert_text(text):\n",
    "    text = str(text)\n",
    "    return text\n",
    "\n",
    "def convert_class_label(class_label):\n",
    "    class_label = class_label.numpy()\n",
    "    return int(class_label[0])\n",
    "\n",
    "def convert(deeplake_path, h5_path):\n",
    "    deeplake_dataset = deeplake.load(deeplake_path)\n",
    "    deeplake_dataset.summary()\n",
    "    h5_path.unlink(missing_ok=True)\n",
    "    \n",
    "    with h5py.File(h5_path, 'w') as h5_file:\n",
    "        tensors = {}\n",
    "        datasets = []\n",
    "        transform = []\n",
    "\n",
    "        for name in deeplake_dataset.tensors:\n",
    "            if name != \"Video\":\n",
    "                tensor = deeplake_dataset.tensors[name]\n",
    "                dtype = None\n",
    "                if tensor.htype == \"audio\":\n",
    "                    dtype = h5py.vlen_dtype(np.dtype('float32'))\n",
    "                    transform.append(convert_audio)\n",
    "                elif tensor.htype == \"text\":\n",
    "                    dtype = h5py.string_dtype(encoding='utf-8', length=None)\n",
    "                    transform.append(convert_text)\n",
    "                elif tensor.htype == \"class_label\":\n",
    "                    label_map = {class_name: i for i, class_name in enumerate(tensor.info[\"class_names\"])}\n",
    "                    dtype = h5py.enum_dtype(label_map, basetype='i')\n",
    "                    transform.append(convert_class_label)\n",
    "                tensors[name] = None\n",
    "                datasets.append(\n",
    "                    h5_file.create_dataset(name, shape=(tensor.shape[0],), dtype=dtype)\n",
    "                )\n",
    "        loader = deeplake_dataset.pytorch(\n",
    "            transform=tensors,\n",
    "            num_workers=1,\n",
    "            shuffle=False,\n",
    "            batch_size=1,\n",
    "            pin_memory=False,\n",
    "            prefetch_factor=10,\n",
    "            progressbar=True,\n",
    "        )\n",
    "        for i, sample in enumerate(loader):\n",
    "            for j, data in enumerate(sample):\n",
    "                data = transform[j](data[0])\n",
    "                datasets[j][i] = data\n",
    "\n",
    "convert(VOXCELEB1_DEEPLAKE, VOXCELEB1_H5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Jan 11 2023, 15:12:53) [GCC 10.2.1 20210110]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "861a2f8c09f43a1383d5cddabe28a76b37a3607cb0ad9545d15c6c4469d688dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
