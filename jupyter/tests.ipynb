{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(\"/workspaces/SpeakerVerification\")\n",
    "\n",
    "DATA = ROOT / \"data\"\n",
    "\n",
    "VOXCELEB1 = DATA / \"voxceleb1\"\n",
    "VOXCELEB2 = DATA / \"voxceleb2\"\n",
    "\n",
    "VOXCELEB1_DEEPLAKE = VOXCELEB1 / \"deeplake\" / \"VoxCeleb1\"\n",
    "VOXCELEB2_DEEPLAKE = VOXCELEB2 / \"deeplake\" / \"VoxCeleb2\"\n",
    "\n",
    "VOXCELEB1_H5 = VOXCELEB1 / \"h5\" / \"MEL__F_512__M_40__W_0.025s__H_0.01s__D_4.00s.hdf5\"\n",
    "VOXCELEB2_H5 = VOXCELEB2 / \"h5\" / \"MEL__F_512__M_40__W_0.025s__H_0.01s__D_2.00s.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "/workspaces/SpeakerVerification/data/voxceleb1/deeplake/VoxCeleb1 loaded successfully.\n",
      "Dataset(path='/workspaces/SpeakerVerification/data/voxceleb1/deeplake/VoxCeleb1', tensors=['Audio', 'Gender', 'Nationality', 'Sample Name', 'Set', 'Speaker ID', 'VGGFace1 ID', 'Video'])\n",
      "\n",
      "   tensor        htype               shape              dtype  compression\n",
      "   -------      -------             -------            -------  ------- \n",
      "    Audio        audio     (153516, 63361:2318721, 1)   None      wav   \n",
      "   Gender     class_label         (153516, 1)          uint32    None   \n",
      " Nationality  class_label         (153516, 1)          uint32    None   \n",
      " Sample Name     text             (153516, 1)            str     None   \n",
      "     Set      class_label         (153516, 1)          uint32    None   \n",
      " Speaker ID   class_label         (153516, 1)          uint32    None   \n",
      " VGGFace1 ID  class_label         (153516, 1)          uint32    None   \n",
      "    Video     class_label         (153516, 1)          uint32    None   \n",
      "\n",
      "============================================\n",
      "/workspaces/SpeakerVerification/data/voxceleb2/deeplake/VoxCeleb2 loaded successfully.\n",
      "Dataset(path='/workspaces/SpeakerVerification/data/voxceleb2/deeplake/VoxCeleb2', tensors=['Audio', 'Gender', 'Sample Name', 'Set', 'Speaker ID', 'VGGFace2 ID', 'Video'])\n",
      "\n",
      "   tensor        htype                shape              dtype  compression\n",
      "   -------      -------              -------            -------  ------- \n",
      "    Audio        audio     (1128246, 63488:3523584, 1)   None      wav   \n",
      "   Gender     class_label         (1128246, 1)          uint32    None   \n",
      " Sample Name     text             (1128246, 1)            str     None   \n",
      "     Set      class_label         (1128246, 1)          uint32    None   \n",
      " Speaker ID   class_label         (1128246, 1)          uint32    None   \n",
      " VGGFace2 ID  class_label         (1128246, 1)          uint32    None   \n",
      "    Video     class_label         (1128246, 1)          uint32    None   \n"
     ]
    }
   ],
   "source": [
    "import deeplake\n",
    "\n",
    "print(\"============================================\")\n",
    "vox1_dataset = deeplake.load(str(VOXCELEB1_DEEPLAKE))\n",
    "vox1_dataset.summary()\n",
    "print()\n",
    "print(\"============================================\")\n",
    "vox2_dataset = deeplake.load(str(VOXCELEB2_DEEPLAKE))\n",
    "vox2_dataset.summary()\n",
    "\n",
    "# 960152\n",
    "# 962431\n",
    "# 965006\n",
    "#\n",
    "\n",
    "# 1128246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying dataset: 100%|██████████| 36275/36275 [7:26:58<00:00  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://lazarnerd/VoxCeleb2Raw loaded successfully.\n",
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/lazarnerd/VoxCeleb2Raw\n",
      "Your Hub dataset has been successfully created!\n",
      "The dataset is private so make sure you are logged in!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset(path='hub://lazarnerd/VoxCeleb2Raw', tensors=['Audio', 'Gender', 'Sample Name', 'Set', 'Speaker ID', 'VGGFace2 ID', 'Video'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = \"eyJhbGciOiJIUzUxMiIsImlhdCI6MTY3NDQ4MzY2NSwiZXhwIjoxNzA2MDE5NTk5fQ.eyJpZCI6ImxhemFybmVyZCJ9.0Rq4Vd4PNLtE6aGaaoI6aAhvJj9V4JKKDyJbBGSy9MW9iwQegzA-R8-v-93asQR99yS12BQsZVwi8DRFNkIYDw\"\n",
    "\n",
    "deeplake.deepcopy(src=VOXCELEB2_DEEPLAKE, dest=\"hub://lazarnerd/VoxCeleb2Raw\", token=token, public=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "batch_size = 800\n",
    "num_workers = 8\n",
    "num_threads = 10\n",
    "num_epochs = 10\n",
    "num_prefetch = 10\n",
    "\n",
    "sample_length = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51268"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1831 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(\"/workspaces/SpeakerVerification\")\n",
    "DATA = ROOT / \"data\"\n",
    "VOXCELEB2 = DATA / \"voxceleb2\" / \"extracted\"\n",
    "\n",
    "m4as = []\n",
    "def build_stat(p: Path):\n",
    "    global m4as\n",
    "    if p.is_dir():\n",
    "        for file in p.iterdir():\n",
    "            build_stat(file)\n",
    "    else:\n",
    "        if p.suffix == \".m4a\":\n",
    "            m4as.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "left = []\n",
    "for p in tqdm(m4as):\n",
    "    if p.exists():\n",
    "        left.append(p)\n",
    "m4as = left\n",
    "\n",
    "print(f\"% Done: {(1128246 - len(m4as)) / 1128246 * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_stat(VOXCELEB2)\n",
    "\n",
    "print(f\"M4A:    {num_m4as}\")\n",
    "print(f\"WAV:    {num_wavs}\")\n",
    "print(f\"Total:  {num_m4as + num_wavs}\")\n",
    "print(f\"% Done: {num_wavs / (num_m4as + num_wavs) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import deeplake\n",
    "import random\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "\n",
    "ROOT = Path(\"/workspaces/SpeakerVerification\")\n",
    "\n",
    "DATA = ROOT / \"data\"\n",
    "\n",
    "VOXCELEB1 = DATA / \"voxceleb1\"\n",
    "VOXCELEB2 = DATA / \"voxceleb2\"\n",
    "\n",
    "VOXCELEB1_DEEPLAKE = VOXCELEB1 / \"deeplake\" / \"MEL__F_512__M_40__W_0.025s__H_0.01s__D_4.00s\"\n",
    "VOXCELEB2_DEEPLAKE = VOXCELEB2 / \"deeplake\" / \"MEL__F_512__M_40__W_0.025s__H_0.01s__D_2.00s\"\n",
    "\n",
    "VOXCELEB1_H5 = VOXCELEB1 / \"h5\" / \"MEL__F_512__M_40__W_0.025s__H_0.01s__D_4.00s.hdf5\"\n",
    "VOXCELEB2_H5 = VOXCELEB2 / \"h5\" / \"MEL__F_512__M_40__W_0.025s__H_0.01s__D_2.00s.hdf5\"\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "num_workers = 8\n",
    "num_threads = 10\n",
    "num_epochs = 10\n",
    "num_prefetch = 10\n",
    "\n",
    "sample_length = 200\n",
    "\n",
    "import os\n",
    "os.environ[\"DEEPLAKE_DOWNLOAD_PATH\"] = str(DATA / \"hub_cache\")\n",
    "dataset = deeplake.load(str(VOXCELEB2_DEEPLAKE))\n",
    "dataset.summary()\n",
    "\n",
    "def transform(spectrogram):\n",
    "    start = random.randint(0, spectrogram.shape[1] - sample_length)\n",
    "    return spectrogram[:, start:start + sample_length]\n",
    "\n",
    "tform = transforms.Compose([\n",
    "    transforms.RandomRotation(20), # Image augmentation\n",
    "    transforms.ToTensor(), # Must convert to pytorch tensor for subsequent operations to run\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = dataset.dataloader()\n",
    "dataloader = dataloader.shuffle()\n",
    "dataloader = dataloader.batch(batch_size)\n",
    "dataloader = dataloader.transform({'spectrograms': None, 'labels': None})\n",
    "dataloader = dataloader.pytorch(\n",
    "    num_workers = num_workers,\n",
    "    num_threads = num_threads,\n",
    "    prefetch_factor = num_prefetch,\n",
    "    persistent_workers = True,\n",
    ")\n",
    "\n",
    "epoch_times = []\n",
    "shuffle_buffer = []\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    start_epoch = time.time()\n",
    "    for i, data in enumerate(dataloader):\n",
    "        if len(shuffle_buffer) < epoch + 1:\n",
    "            shuffle_buffer.append(time.time() - start_epoch)\n",
    "    epoch_times.append(time.time() - start_epoch)\n",
    "    print()\n",
    "    print(f\"Shuffle Buffer: {shuffle_buffer[-1]:6.2f}s\")\n",
    "    print(f\"Epoch:          {epoch_times[-1]:6.2f}s\")\n",
    "    print()\n",
    "    print()\n",
    "print(\"============================================\")\n",
    "print(f\"Total time: {time.time() - start:6.2f}s\")\n",
    "print(f\"Avg time:   {sum(epoch_times) / len(epoch_times):6.2f}s\")\n",
    "print(f\"Min time:   {min(epoch_times):6.2f}s\")\n",
    "print(f\"Max time:   {max(epoch_times):6.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = dataset.pytorch(\n",
    "    num_workers = num_workers,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    tensors=['spectrograms', 'labels'],\n",
    "    num_threads = num_threads,\n",
    "    prefetch_factor = num_prefetch,\n",
    "    persistent_workers = True,\n",
    ")\n",
    "\n",
    "epoch_times = []\n",
    "shuffle_buffer = []\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    start_epoch = time.time()\n",
    "    for i, data in enumerate(dataloader):\n",
    "        if len(shuffle_buffer) < epoch + 1:\n",
    "            shuffle_buffer.append(time.time() - start_epoch)\n",
    "    epoch_times.append(time.time() - start_epoch)\n",
    "    print()\n",
    "    print(f\"Shuffle Buffer: {shuffle_buffer[-1]:6.2f}s\")\n",
    "    print(f\"Epoch:          {epoch_times[-1]:6.2f}s\")\n",
    "    print()\n",
    "    print()\n",
    "print(\"============================================\")\n",
    "print(f\"Total time: {time.time() - start:6.2f}s\")\n",
    "print(f\"Avg time:   {sum(epoch_times) / len(epoch_times):6.2f}s\")\n",
    "print(f\"Min time:   {min(epoch_times):6.2f}s\")\n",
    "print(f\"Max time:   {max(epoch_times):6.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epoch_times = []\n",
    "shuffle_buffer = []\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    start_epoch = time.time()\n",
    "    for i, data in enumerate(dataloader):\n",
    "        if len(shuffle_buffer) < epoch:\n",
    "            shuffle_buffer.append(time.time() - start_epoch)\n",
    "    epoch_times.append(time.time() - start_epoch)\n",
    "    print()\n",
    "    print(f\"Shuffle Buffer: {shuffle_buffer[-1]:6.2f}s\")\n",
    "    print(f\"Epoch:          {epoch_times[-1]:6.2f}s\")\n",
    "    print()\n",
    "    print()\n",
    "print(\"============================================\")\n",
    "print(f\"Total time: {time.time() - start:6.2f}s\")\n",
    "print(f\"Avg time:   {sum(epoch_times) / len(epoch_times):6.2f}s\")\n",
    "print(f\"Min time:   {min(epoch_times):6.2f}s\")\n",
    "print(f\"Max time:   {max(epoch_times):6.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(\"/workspaces/SpeakerVerification\")\n",
    "\n",
    "DATA = ROOT / \"data\"\n",
    "\n",
    "VOXCELEB1 = DATA / \"voxceleb1\"\n",
    "VOXCELEB2 = DATA / \"voxceleb2\"\n",
    "\n",
    "VOXCELEB1_DEEPLAKE = VOXCELEB1 / \"deeplake\" / \"MEL__F_512__M_40__W_0.025s__H_0.01s__D_4.00s\"\n",
    "VOXCELEB2_DEEPLAKE = VOXCELEB2 / \"deeplake\" / \"MEL__F_512__M_40__W_0.025s__H_0.01s__D_2.00s\"\n",
    "\n",
    "VOXCELEB1_H5 = VOXCELEB1 / \"h5\" / \"MEL__F_512__M_40__W_0.025s__H_0.01s__D_4.00s.hdf5\"\n",
    "VOXCELEB2_H5 = VOXCELEB2 / \"h5\" / \"MEL__F_512__M_40__W_0.025s__H_0.01s__D_2.00s.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 800\n",
    "num_workers = 8\n",
    "num_epochs = 2\n",
    "num_prefetch = 16\n",
    "sample_length = 390\n",
    "\n",
    "deeplake_path = VOXCELEB2_DEEPLAKE\n",
    "h5_path = VOXCELEB1_H5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Queue, Process\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import h5py\n",
    "import time\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "\n",
    "indices = []\n",
    "with h5py.File(h5_path, \"r\") as f:\n",
    "    labels = f[\"y\"][:]\n",
    "    for i in range(labels.shape[0]):\n",
    "        label = labels[i]\n",
    "        indices.append((label[1], label[2], label[2] - label[1] - sample_length))\n",
    "\n",
    "indices = np.array(indices)\n",
    "\n",
    "def get_batch_indices():\n",
    "    starts = np.random.randint(0, indices[:,2])\n",
    "    ends = starts + sample_length\n",
    "\n",
    "    epoch_indices = np.array([indices[:,0], indices[:,1]]).T\n",
    "    print(epoch_indices.shape)\n",
    "    np.random.shuffle(epoch_indices)\n",
    "\n",
    "\n",
    "    batch_indices = []\n",
    "\n",
    "    if epoch_indices.shape[0] % batch_size != 0:\n",
    "        remainder = epoch_indices.shape[0] % batch_size\n",
    "        batch_indices.append(epoch_indices[-remainder:])\n",
    "        epoch_indices = epoch_indices[:-remainder]\n",
    "\n",
    "    batch_indices.extend(np.split(epoch_indices, epoch_indices.shape[0] // batch_size))\n",
    "    return batch_indices\n",
    "    \n",
    "class H5Worker:\n",
    "    def __init__(self, index_queue, sample_queue, h5_path, sample_length):\n",
    "        self.index_queue = index_queue\n",
    "        self.sample_queue = sample_queue\n",
    "        self.h5_path = h5_path\n",
    "        self.sample_length = sample_length\n",
    "    \n",
    "    def work(self):\n",
    "        with h5py.File(self.h5_path, \"r\") as f:\n",
    "            x_dataset = f[\"x\"]\n",
    "            while True:\n",
    "                batch_indices = self.index_queue.get()\n",
    "                batch = []\n",
    "                for i in range(batch_indices.shape[0]):\n",
    "                    start, end = batch_indices[i]\n",
    "                    sample = x_dataset[int(start):int(end), :]\n",
    "                    s = np.random.randint(0, sample.shape[0] - self.sample_length)\n",
    "                    e = int(s + self.sample_length)\n",
    "                    #print(f\"{s}, {e}\")\n",
    "                    batch.append(sample[s:e, :])\n",
    "                self.sample_queue.put(np.array(batch))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "index_queue = Queue()\n",
    "sample_queue = Queue(num_prefetch)\n",
    "\n",
    "workers = []\n",
    "for i in range(num_workers):\n",
    "    worker = H5Worker(index_queue, sample_queue, h5_path, sample_length)\n",
    "    workers.append(Process(target=worker.work))\n",
    "    workers[-1].start()\n",
    "\n",
    "\n",
    "times = []\n",
    "print(\"starting\")\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    start_ = time.time()\n",
    "    batch_indices = get_batch_indices()\n",
    "    for batch in batch_indices:\n",
    "        index_queue.put(batch)\n",
    "\n",
    "    for i in trange(len(batch_indices)):\n",
    "        batch = sample_queue.get()\n",
    "    times.append(time.time() - start_)\n",
    "    print(f\"Epoch {epoch:2d}:   {times[-1]:6.2f}s\")\n",
    "print(f\"Total time: {time.time() - start:6.2f}s\")\n",
    "print(f\"Avg time:   {sum(times) / len(times):6.2f}s\")\n",
    "print(f\"Min time:   {min(times):6.2f}s\")\n",
    "print(f\"Max time:   {max(times):6.2f}s\")\n",
    "while True:\n",
    "    for worker in workers:\n",
    "        try:\n",
    "            worker.terminate()\n",
    "        except:\n",
    "            pass\n",
    "    running = []\n",
    "    for worker in workers:\n",
    "        running.append(worker.is_alive())\n",
    "    if not any(running):\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "import random\n",
    "\n",
    "def transform(spectrogram):\n",
    "    start = random.randint(0, spectrogram.shape[1] - sample_length)\n",
    "    return spectrogram[:, start:start+sample_length]\n",
    "\n",
    "dataset = deeplake.load(deeplake_path)\n",
    "dataloader = dataset.pytorch(\n",
    "    num_workers = num_workers,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    transform={'spectrograms': transform, 'labels': None},\n",
    "    prefetch_factor = num_prefetch,\n",
    "    persistent_workers = True,\n",
    ")\n",
    "\n",
    "epoch_times = []\n",
    "shuffle_buffer = []\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    start_epoch = time.time()\n",
    "    for i, data in enumerate(dataloader):\n",
    "        if len(shuffle_buffer) < epoch + 1:\n",
    "            shuffle_buffer.append(time.time() - start_epoch)\n",
    "    epoch_times.append(time.time() - start_epoch)\n",
    "    print()\n",
    "    print(f\"Shuffle Buffer: {shuffle_buffer[-1]:6.2f}s\")\n",
    "    print(f\"Epoch:          {epoch_times[-1]:6.2f}s\")\n",
    "    print()\n",
    "    print()\n",
    "print(\"============================================\")\n",
    "print(f\"Total time: {time.time() - start:6.2f}s\")\n",
    "print(f\"Avg time:   {sum(epoch_times) / len(epoch_times):6.2f}s\")\n",
    "print(f\"Min time:   {min(epoch_times):6.2f}s\")\n",
    "print(f\"Max time:   {max(epoch_times):6.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = np.random.randint(0, indices[:,1])\n",
    "ends = starts + sample_length\n",
    "\n",
    "epoch_indices = np.array([indices[:,0], starts, ends]).T\n",
    "np.random.shuffle(epoch_indices)\n",
    "\n",
    "\n",
    "print(epoch_indices.shape[0] / batch_size)\n",
    "\n",
    "batch_indices = []\n",
    "\n",
    "if epoch_indices.shape[0] % batch_size != 0:\n",
    "    remainder = epoch_indices.shape[0] % batch_size\n",
    "    batch_indices.append(epoch_indices[-remainder:])\n",
    "    epoch_indices = epoch_indices[:-remainder]\n",
    "\n",
    "batch_indices.extend(np.split(epoch_indices, epoch_indices.shape[0] // batch_size))\n",
    "\n",
    "print(len(batch_indices))\n",
    "print(batch_indices[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Queue, Process\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "class DeeplakeWorker:\n",
    "    def __init__(self, index_queue, sample_queue, deeplake_path, sample_length):\n",
    "        self.index_queue = index_queue\n",
    "        self.sample_queue = sample_queue\n",
    "        self.deeplake_path = str(deeplake_path)\n",
    "        self.sample_length = sample_length\n",
    "    \n",
    "    def work(self):\n",
    "        ds = deeplake.load(self.deeplake_path)\n",
    "        with ds:\n",
    "            while True:\n",
    "                batch_indices = self.index_queue.get()\n",
    "                batch = []\n",
    "                for i in range(batch_indices.shape[0]):\n",
    "                    idx, start, end = batch_indices[i]\n",
    "                    idx = int(idx)\n",
    "                    start = int(start)\n",
    "                    end = int(end)\n",
    "                    batch.append(ds.spectrograms[idx, :, start:end].numpy())\n",
    "                self.sample_queue.put(np.array(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "index_queue = Queue()\n",
    "sample_queue = Queue(10)\n",
    "\n",
    "\n",
    "for batch in batch_indices:\n",
    "    index_queue.put(batch)\n",
    "\n",
    "workers = []\n",
    "for i in range():\n",
    "    worker = DeeplakeWorker(index_queue, sample_queue, VOXCELEB2_DEEPLAKE, sample_length)\n",
    "    workers.append(Process(target=worker.work))\n",
    "    workers[-1].start()\n",
    "\n",
    "start = time.time()\n",
    "for i in range(len(batch_indices)):\n",
    "    batch = sample_queue.get()\n",
    "    print(f\"{i:3d} - {time.time() - start:6.2f}s\")\n",
    "print(f\"Total time: {time.time() - start:6.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Jan 11 2023, 15:12:53) [GCC 10.2.1 20210110]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "861a2f8c09f43a1383d5cddabe28a76b37a3607cb0ad9545d15c6c4469d688dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
